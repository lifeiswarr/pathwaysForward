# [[VANITY]]. [[ML_Engineer_Mastery_Roadmap]].

## 1. Fundamentals
- [ ] Understand what LangChain is & its purpose
- [ ] Learn LLM basics and API integration
- [ ] Install & set up LangChain environment

## 2. Core Concepts
- [ ] PromptTemplates
- [ ] Chains
- [ ] Agents & Tools
- [ ] Memory

## 3. Data Connections
- [ ] Document Loaders
- [ ] Text Splitters
- [ ] Embedding generation
- [ ] VectorStores (FAISS, Pinecone, Chroma)

## 4. Retrieval-Augmented Generation (RAG) in LangChain
- [ ] RetrievalQA chains
- [ ] ConversationalRetrievalQA
- [ ] Contextual compression retrievers

## 5. Agents & Tooling
- [ ] Built-in agents
- [ ] Custom tools
- [ ] Multi-agent workflows

## 6. Integrations
- [ ] OpenAI, Hugging Face, Anthropic, Cohere APIs
- [ ] Vector databases (Pinecone, Weaviate, Milvus, FAISS)
- [ ] APIs & web scraping tools

## 7. Advanced Patterns
- [ ] LangGraph for complex workflows
- [ ] Asynchronous chains
- [ ] Parallel tool execution

## 8. Deployment & Scaling
- [ ] Deploy LangChain apps on FastAPI/Flask
- [ ] Use LangServe for serving
- [ ] Cloud deployment (AWS, GCP, Azure)

## 9. Testing & Evaluation
- [ ] Unit testing for LangChain chains
- [ ] LLM response evaluation
- [ ] Continuous improvement of LangChain apps
